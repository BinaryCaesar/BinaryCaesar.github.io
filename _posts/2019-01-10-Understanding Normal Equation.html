<!DOCTYPE html>
<html>
<head>
<title>2019-01-10-Understanding Normal Equation.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
	font-size: 14px;
	padding: 0 12px;
	line-height: 22px;
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}


body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	color: #4080D0;
	text-decoration: none;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

h1 code,
h2 code,
h3 code,
h4 code,
h5 code,
h6 code {
	font-size: inherit;
	line-height: auto;
}

a:hover {
	color: #4080D0;
	text-decoration: underline;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left: 5px solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 14px;
	line-height: 19px;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

.mac code {
	font-size: 12px;
	line-height: 18px;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

/** Theming */

.vscode-light,
.vscode-light pre code {
	color: rgb(30, 30, 30);
}

.vscode-dark,
.vscode-dark pre code {
	color: #DDD;
}

.vscode-high-contrast,
.vscode-high-contrast pre code {
	color: white;
}

.vscode-light code {
	color: #A31515;
}

.vscode-dark code {
	color: #D7BA7D;
}

.vscode-light pre:not(.hljs),
.vscode-light code > div {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre:not(.hljs),
.vscode-dark code > div {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre:not(.hljs),
.vscode-high-contrast code > div {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

.vscode-light blockquote,
.vscode-dark blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.vscode-high-contrast blockquote {
	background: transparent;
	border-color: #fff;
}
</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family:  "Meiryo", "Segoe WPC", "Segoe UI", "SFUIText-Light", "HelveticaNeue-Light", sans-serif, "Droid Sans Fallback";
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

</head>
<body>
<hr>
<h2 id="layout-posttitle-understanding-normal-equationsubtitle-%E4%BB%80%E4%B9%88%E6%98%AF-normal-equation-%E5%A6%82%E4%BD%95%E6%8E%A8%E5%AF%BC-%E6%9C%89%E4%BB%80%E4%B9%88%E6%B7%B1%E5%B1%82%E5%90%AB%E4%B9%89date-2019-01-10-234500-0800background-imgposts2019-01-10jpg">layout: post
title:  &quot;Understanding Normal Equation&quot;
subtitle: &quot;什么是 Normal Equation? 如何推导? 有什么深层含义?&quot;
date:   2019-01-10 23:45:00 +0800
background: '/img/posts/2019-01-10.jpg'</h2>
<h1 id="%E7%90%86%E8%A7%A3-normal-equation">理解 Normal Equation</h1>
<p>Normal Equation 是线性回归方程中,一种求最佳拟合系数的最小二乘方法.与机器学习中常见的多次迭代,逐渐逼近的方式不同,Normal Equation可以直接通过矩阵运算求得拟合系数.</p>
<p>$$\theta=(X^TX)^{-1}X^Ty\tag{1}$$
其中 $\theta$ 为待估参数:
$$
\theta=
\begin{bmatrix}
\theta_0 &amp; \theta_1 &amp; \theta_2 &amp; \cdots &amp; \theta_n \
\end{bmatrix}^T\tag{2}
$$</p>
<p>$X$,$y$ 为写成矩阵形式的数据,</p>
<p>$$
X=
\begin{bmatrix}
x^{(1)} \ x^{(2)} \ \vdots \ x^{(m)} \
\end{bmatrix}=
\begin{bmatrix}
x^{(1)}_1 &amp; x^{(1)}_2 &amp; \cdots &amp; x^{(1)}_n \
x^{(2)}_1 &amp; x^{(2)}_2 &amp; \cdots &amp; x^{(2)}_n \
\vdots    &amp; \vdots    &amp; \ddots &amp; \vdots    \
x^{(m)}_1 &amp; x^{(m)}_2 &amp; \cdots &amp; x^{(m)}_n \
\end{bmatrix}
\quad \quad
y=
\begin{bmatrix}
y^{(1)} \ y^{(2)} \ \vdots \ y^{(m)} \
\end{bmatrix}\tag{3}
$$</p>
<font size = '1'>
<p>注：为避免混淆,本文中所有涉及到的矩阵计算均采用分子布局,详情请参考
<a href="https://en.wikipedia.org/wiki/Matrix_calculus/" title="Matrix Calculus">Matrix Calculus</a>.</p>
</font>
<br/>
<h2 id="1-%E6%8E%A8%E5%AF%BC%E8%BF%87%E7%A8%8B">1. 推导过程</h2>
<p>下面依次介绍3种推导方法</p>
<h3 id="11-%E7%A1%AC%E7%AE%97">1.1 硬算</h3>
<p>最简单粗暴的方法.<br/>
根据最小二乘的定义,求 $\theta$ 使得预测值与实际观测值的均方误差最小,也即</p>
<p>$$\overline{\theta} = arg\ min(\frac{1}{2m}\sum_{i=1}^m (x^{(i)} \cdot \theta\ -y_i)^2)\tag{(4)}$$</p>
<p>右边括号中的值即为均方误差</p>
<p>$$\frac{1}{2m}\sum_{i=1}^m (x^{(i)} \cdot \theta\ -y_i)^2)$$</p>
<font size = '1'>
<p>注：此处为了后续求导时方便计算,将系数的分母乘以了2</p>
</font>
<p>上式是一个关于 $\theta$ 的二次多项式,明显存在最小值,且在 $\theta$ 的导数为0处取得.对 $\theta$ 的各个分量求导,可得</p>
<p>$$
\begin{cases}
\frac{1}{m}\sum_{i=1}^m (x^{(i)} \cdot \theta\ -y^{(i)})x_0^{(i)}=0 \
\frac{1}{m}\sum_{i=1}^m (x^{(i)} \cdot \theta\ -y^{(i)})x_1^{(i)}=0 \
\quad \cdots \
\frac{1}{m}\sum_{i=1}^m (x^{(i)} \cdot \theta\ -y^{(i)})x_n^{(i)}=0 \
\end{cases}
$$</p>
<p>写为矩阵形式即为

$$
\frac{1}{m}
\begin{bmatrix}
x^{(1)}\cdot\theta-y^{(1)} \
x^{(2)}\cdot\theta-y^{(2)} \
\cdots \
x^{(m)}\cdot\theta-y^{(m)} \
\end{bmatrix}^T
\cdot
\begin{bmatrix}
x_0^{(1)} &amp; x_1^{(1)} &amp; \cdots &amp; x_n^{(1)} \
x_0^{(2)} &amp; x_1^{(2)} &amp; \cdots &amp; x_n^{(2)} \
\vdots    &amp; \vdots    &amp; \ddots &amp; \vdots    \
x_0^{(m)} &amp; x_1^{(m)} &amp; \cdots &amp; x_n^{(m)} \
\end{bmatrix}=
\begin{bmatrix}
0 &amp; 0 &amp; \cdots &amp; 0 \
\end{bmatrix}_{m \times 1}
$$</p>
<p>约去 $\frac{1}{m}$ ,将 $(2),(3)$ 式代入,并两边取逆,可得</p>
<p>$$
X^T(X\theta-y)=0
$$
$$
X^TX\theta=X^Ty
$$
$$
\theta=(X^TX)^{-1}X^Ty
$$</p>
<p>也就得到了 Normal Equation $(1)$.</p>
<font size = '1'>
<p>*后续会讨论 $X^TX$ 不可逆的情况.</p>
</font>
<br/>
<h3 id="12-%E7%9F%A9%E9%98%B5%E5%BE%AE%E7%A7%AF%E5%88%86">1.2 矩阵微积分</h3>
<p>同之前的思路相同,对 $\theta$ 求导,在其导数为0处取得最小值.但是不需要展开矩阵,可以直接通过矩阵微积分的方法,将 $\theta$ 看作一个整体进行求导.</p>
<font size = '1'>
<p>注：矩阵微积分是一种对多变量微积分的标记表示方法,与前述的硬算法其实没有本质上的区别,只是在引进了矩阵微积分的符号系统后,简化了计算推导过程.</p>
</font>
<p>将 $(4)$ 写成矩阵形式即为</p>
<p>$$\frac{1}{2m}(X\theta-y)^T \cdot (X\theta-y))\tag{5}$$</p>
<p>忽略 $\frac{1}{2m}$ ,展开为</p>
<p>$$
\theta^TX^TX\theta - \theta^TX^Ty-y^TX\theta+y^2
$$</p>
<font size = '1'>
<p>注：此式中各项皆为实值标量,对向量求导也就是对向量的各分量求导,并按照该向量的shape返回结果.标量对向量求导具体可参考 <a href="https://en.wikipedia.org/wiki/Matrix_calculus/" title="Matrix Calculus">Matrix Calculus</a> ,此处直接使用了相关的公式：</p>
<p>$$
{\frac{\partial{x^Tx}}{\partial{x}}} = x^T(A+A^T)
\quad ; \quad
{\frac{\partial{x^Ta}}{\partial{x}}} = a^T
\quad ; \quad
{\frac{\partial{ax}}{\partial{x}}} = a
$$</p>
<p>具体推导过程此处不再展开,可参考 <a href="https://web.stanford.edu/~jduchi/projects/matrix_prop.pdf/" title="Properties of the Trace and Matrix Derivatives">Properties of the Trace and Matrix Derivatives</a>.<br/>
千万注意,关于矩阵微积分,不同作者的矩阵排布方式可能不同,同样的表达式,分子布局和分母布局的结果可能会差个转置或运算顺序,务必确认具体采用的是哪种布局,不然极容易出错.
</font></p>
<p>对 $\theta$ 求导,可得
$$
\theta^T(X^TX+X^TX)-y^TX-y^TX=0
$$
化简可得
$$
X^TX\theta=X^Ty
$$
$$
\theta=(X^TX)^{-1}X^Ty
$$
<br/></p>
<p>另外,也可以根据链式求导法则,直接对 $(8)$ 直接求导,得到</p>
<p>$$
\frac{\partial{((X\theta-y)^T \cdot (X\theta-y))}}{\partial{\theta}}=
\frac{\partial{((X\theta-y)^T \cdot (X\theta-y))}}{\partial{(X\theta-y)}} \cdot
\frac{\partial{(X\theta-y)}}{\partial{(\theta)}}=
$$
$$
2(X\theta-y)^T \cdot X=0
$$</p>
<p>化简后可得</p>
<p>$$
\theta=(X^TX)^{-1}X^Ty
$$
<br/></p>
<h3 id="13-%E5%87%A0%E4%BD%95%E6%84%8F%E4%B9%89%E6%8E%A8%E5%AF%BC">1.3 几何意义推导</h3>
<p>在理想情况下,我们实际上是想找到一组 $\theta$ ,满足</p>
<p>$$X\theta=y\tag{6}$$
完美地刻画出X与y之间的线性关系,但是因为误差原因,这在实际中是基本无法得到的.所以退而求其次,我们希望最小化 $X\theta$ 与 $y$ 之间的差异.注意到 $X\theta$ 实际上是 $X$ 的列向量的线性组合,那么我们的目标也可以看作：在 $X$ 的列空间中找到一个向量,使其与y的$^*$距离最近.其实也就是寻找 $y$ 在 $X$ 的列空间中的投影.而若 $X\theta$ 为投影向量,那么误差向量 $(X\theta-y)$ 与 $X$ 的列向量必定是相互垂直的.于是有
$$
X^T(X\theta-y)=0
$$
$$
X^TX\theta=X^Ty\tag{7}
$$
$$
\theta=(X^TX)^{-1}X^Ty
$$</p>
<font size = '1'>
<p>$^*$习惯上,我们说的距离都是指欧氏距离,这其实也是最小二乘中平方的本质.</p>
</font>
<br/>
<br/>
<h2 id="2-%E6%9B%B4%E8%BF%9B%E4%B8%80%E6%AD%A5">2. 更进一步</h2>
<p>回到 $(6)$ ,我们最朴素但也最容易落空的想法是根据此式直接解出 $\theta$ ,可是普遍的情况下, $m&gt;n$ ,这是个超定方程组, $X_{m \times n}$ 的逆不存在.</p>
<p>但是再看 $(7)$ ,这是得出Normal Equation 的前一步,然而从形式上看,只是在 $(6)$ 的等式两端分别左乘了 $X^T$ .为什么这样就能求得超定方程组 $(9)$ 的最小二乘解？</p>
<p>回到 $X\theta=y$ ,若 $X$ 可逆,那么可以直接等式两边左乘 $X^{-1}$ ,得到 $\theta=X^{-1}y$, 而当 $X$ 不可逆的时候,想要达到类似的效果,可以采用 $X$ 的伪逆 $X^+$ (或称作广义逆),其中最广为人知的即为 Moore–Penrose inverse,具体可以参考 <a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse" title="Moore–Penrose inverse">Moore–Penrose inverse</a> .</p>
<p>根据其定义, $X^+$ 需满足下述条件中的1个或多个:</p>
<p>$$
XX^+X=X\tag{a}
$$</p>
<p>$$
X^+XX^+=X^+\tag{b}
$$
$$
(XX^+)^<em>=XX^+\tag{c}
$$
$$
(X^+X)^</em>=X^+X\tag{d}
$$</p>
<font size = '1'>
<p>注：由于我们讨论的 $X$ 都是实值矩阵,所以 $A^*=A^T$ .</p>
</font>
<p>将 $(c)$ 展开,得到
$$(X^+)^TX^T=XX^+$$
两端右乘 $X$
$$(X^+)^TX^TX=XX^+X$$
将 $(1)$ 代入右端
$$(X^+)^TX^TX=X$$
$$X^TXX^+=X^T$$
注意到当 $X$ 的列向量线性独立时,
$X_{n \times m}^T \cdot X_{n \times m}$
是一个 $n \times n$ 且秩为n的方阵,可逆,于是有
$$X^+=(X^TX)^{-1}X^T$$</p>
<p>$$
X^+=(X^TX)^{-1}X^T\tag{8}
$$
根据前述思路有</p>
<p>$$
\theta=X^+y=(X^TX)^{-1}X^Ty
$$</p>
<p>注意到我们其实只用到了4条性质中的 $(1)(3)$ 这2条性质,因为其实我们要求的是 $X$ 的左逆,也即找到一个矩阵,使得 $X$ 在其表示的行变换下,变为单位矩阵.</p>
<p>而 $(a)$ 可以看作 $(XX^+)X=(I)X$ ,意义恰恰是在$X$行空间中,上述命题成立.我们只需在此基础上对 $XX^+$ 做处理即可,而 $(3)$ 正是关于 $XX^+$ 的等式.</p>
<font size = '1'>
<p>思考一下,广义右逆怎么推导？</p>
</font>
<br/>
<p>总之,我们又一次得到了 Normal Equation.也就是说,当在 $(9)$ 的两边分别左乘 $X^T$ 的时候,恰好满足了 $X$ 的伪逆的形式.那么左乘其他矩阵,是否能达到类似的效果呢？答案是肯定的.</p>
<br/>
<br/>
<h2 id="3-%08%E5%86%8D%E8%BF%9B%E4%B8%80%E6%AD%A5">3. 再进一步</h2>
<p>注意到 $(8)$ 的成立要求 $X_{n \times m}^T \cdot X_{n \times m}$ 是可逆的,而我们的讨论范围限定在 $m&gt;n$ 的条件下,并且我们知道 $X^TX$与$X$ 是相抵的,即

$$rank(X^TX)=rank(X)=rank(X^T)=n$$</p>
<p>所以在 $X$ 列满秩的情况下, $(X^TX)_{n \times n}$ 确实是可逆的.</p>
<p>也就是说,在 $X\theta=y$ 也即 $X\theta=Iy$ 的两侧分别左乘 $X$ 后,等式左侧并无信息的损失,因为秩没有降.只在等式右侧可能有信息损失.</p>
<font size = '1'>
<p>直觉是等式右侧在左乘 $X$ 时相当于做了一次投影,投影时损失掉的那部分error_vector,但是没有仔细研究,以后有时间了补上~</p>
</font>
<p>所以关键是让等式左侧在左乘一个矩阵之后,变得可逆,这就要求左乘的矩阵的shape应该与 $X^T$ 相同(从而保证运算后是个方阵),同时保持其秩不变.这样的矩阵除了 $X^T$ 外,还存在吗？当然存在.</p>
<p>考虑 $X$ 的QR分解
$$
X_{m \times n} = Q_{m \times n} \cdot R_{n \times n}
$$
其中 $Q_{m \times n}$ 列满秩正交矩阵, $R_{n \times n}$ 为n阶满秩方阵. $Q^T$ 即为我们要找的矩阵.</p>
<p>$$
X\theta=y
$$</p>
<p>$$
QR\theta=y
$$</p>
<p>$$
Q^TQR\theta=Q^Ty
$$</p>
<p>$$
IR\theta=Q^Ty
$$</p>
<p>$$
\theta=R^{-1}Q^Ty
$$</p>
<p>注意左乘矩阵的选择并不惟一,比如 $X^T$ ,又比如 $Q$ 经初等变换得到的矩阵均满足要求.但QR分解计算效率高, $Q^TQ=I$ 这个性质大大简化了计算,并且有很多成熟的算法和包可以高效实现这一过程,所以这也是目前在解线性回归模型时最常用的方法之一.
<br/>
<br/></p>
<h2 id="4-%E5%B0%8F%E7%BB%93">4. 小结</h2>
<p>综上,用最小二乘法处理线性回归问题实际上就是寻找 $y$ 在某一线性空间中的投影向量,这个空间最直观的选择就是 $X$ 本身的列空间,而为了提高计算速度,常选用 $X$ 经QR分解后的得到的正交矩阵 $Q$ 的列空间.</p>
<br/>
<br/>
<h2 id="reference">Reference</h2>
<font size = '2'>
<ol>
<li>
<p>Matrix Calculus: <br/>
<a href="ttps://en.wikipedia.org/wiki/Matrix_calculus/">https://en.wikipedia.org/wiki/Matrix_calculus/</a></p>
</li>
<li>
<p>Properties of the Trace and Matrix Derivatives:<br/>
<a href="https://web.stanford.edu/~jduchi/projects/matrix_prop.pdf/">https://web.stanford.edu/~jduchi/projects/matrix_prop.pdf/</a></p>
</li>
<li>
<p>Moore–Penrose inverse: <br/>
<a href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">https://en.wikipedia.org/wiki/Moore–Penrose_inverse/</a></p>
</li>
<li>
<p>掰开揉碎推导Normal Equation: <br/>
<a href="https://zhuanlan.zhihu.com/p/22757336">https://zhuanlan.zhihu.com/p/22757336/</a></p>
</li>
<li>
<p>5种方法推导 Normal Equation: <br/>
<a href="https://www.cnblogs.com/AngelaSunny/p/6616712.html">https://www.cnblogs.com/AngelaSunny/p/6616712.html/</a></p>
</li>
</ol>
</font>

</body>
</html>
